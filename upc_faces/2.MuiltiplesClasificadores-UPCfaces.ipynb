{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import cv2\n",
    "sys.path.append(\"..\")  # Adds higher directory to python modules path.\n",
    "from img_to_vec import Img2Vec\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from skimage import feature\n",
    "\n",
    "#import torchvision.models as models\n",
    "# model = models.resnet152(pretrained=True)\n",
    "# modules=list(model.modules())[:-1]\n",
    "# print(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikaelnb/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['faces_3', 'faces_2', 'faces_6', 'faces_5', 'faces_7', 'faces_1', 'faces_4']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# input_path = './test_images'\n",
    "#input_path = '/home/mikaelnb/Project/notebooks/YouTubeFacesDB/data'\n",
    "input_path = './UPCfaces/'\n",
    "\n",
    "img2vec = Img2Vec(model='resnet-152')\n",
    "\n",
    "os.listdir(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['faces_1', 'faces_2', 'faces_3', 'faces_4', 'faces_5', 'faces_6', 'faces_7'] {0: 'faces_1', 1: 'faces_2', 2: 'faces_3', 3: 'faces_4', 4: 'faces_5', 5: 'faces_6', 6: 'faces_7'}\n"
     ]
    }
   ],
   "source": [
    "#aligned_folder = '/aligned_images_DB/'\n",
    "new_input_path = input_path# + aligned_folder\n",
    "labels = sorted(os.listdir(new_input_path), key=lambda s: s.lower())#[:4]\n",
    "label_id = {}\n",
    "for i, label in enumerate(labels):\n",
    "    label_id[i] = label\n",
    "print(labels, label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in os.listdir(new_input_path + label):\n",
    "#     print(os.fsdecode(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faces_1\n",
      "faces_2\n",
      "faces_3\n",
      "faces_4\n",
      "faces_5\n",
      "faces_6\n",
      "faces_7\n"
     ]
    }
   ],
   "source": [
    "for asdfdas in label_id:\n",
    "    print(label_id[asdfdas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[None, None, None, None, None, None, None]\n",
      "[[], [], [], [], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "print(len(label_id))\n",
    "#pics = np.empty((len(label_id),0))\n",
    "pics = [None]*len(label_id)\n",
    "print(pics)\n",
    "\n",
    "for index in label_id:\n",
    "    pics[int(index)] = []\n",
    "    \n",
    "print(pics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "index:  0\n",
      "(2048,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikaelnb/.local/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "0 10\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "1 10\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "2 10\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "3 10\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "4 10\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "5 10\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n"
     ]
    }
   ],
   "source": [
    "vec = []\n",
    "labels = []\n",
    "imagesPerLabel = 10\n",
    "\n",
    "testVec = []\n",
    "k = 0\n",
    "\n",
    "for index in label_id:    \n",
    "    for root, dirs, files in os.walk(new_input_path + label_id[index]):\n",
    "        #print(root, dirs, files)\n",
    "        for name in files:\n",
    "            if len(pics[index]) > imagesPerLabel -1:\n",
    "                print(index, len(pics[index]))\n",
    "                break\n",
    "            #print(name)\n",
    "            if name.endswith((\".jpg\")):                \n",
    "                img = Image.open(os.path.join(os.fsdecode(root), name))\n",
    "                #print(os.path.join(os.fsdecode(root), name))\n",
    "                vec = img2vec.get_vec(img)\n",
    "                if  testVec == [] and index == 0:\n",
    "                    k += 1\n",
    "                    if k == 5:\n",
    "                        print('index: ', index)\n",
    "                        testVec = vec\n",
    "                print(vec.shape)                \n",
    "                pics[index].append(vec)     \n",
    "                #print(name)\n",
    "                labels.append(int(index))\n",
    "    pics[index] = np.array(pics[index])    \n",
    "    \n",
    "labels = np.array(labels)\n",
    "\n",
    "# print()\n",
    "# print(pics[0][0:])\n",
    "# print(pics[1][0:])\n",
    "\n",
    "#                 X = vec.T\n",
    "#                 num_components = 128\n",
    "#                 pca = PCA(n_components = num_components, whiten=True).fit(X)\n",
    "\n",
    "#                 X_train = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 2048)\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3\n",
      " 3 3 3 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6]\n"
     ]
    }
   ],
   "source": [
    "pics=np.array(pics)\n",
    "pics = pics.reshape(len(pics)*len(pics[0]),2048)\n",
    "print(pics.shape)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# n=25\n",
    "# randList=[]\n",
    "\n",
    "# for i in range(0,len(pics)):\n",
    "#     randList.append(random.sample(range(imagesPerLabel), n))\n",
    "# randList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newPics = [None]*len(label_id)\n",
    "# for index in label_id:\n",
    "#     newPics[int(index)] = []\n",
    "    \n",
    "# for index in range(0,len(pics)):\n",
    "#     for i in range(0, n):\n",
    "#         newPics[index].append(pics[index][randList[index][i]])\n",
    "#     newPics[index] = np.array(newPics[index])\n",
    "# newPics = np.array(newPics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pics\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 2048) (70,)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "with h5py.File(\"./UPCfaces_hdf5/data_UPCfaces.hdf5\", \"w\") as f:\n",
    "    dset = f.create_dataset(\"dataset_1\", data=np.array(X))\n",
    "\n",
    "#le = LabelEncoder()\n",
    "#target = le.fit_transform(labels)\n",
    "with h5py.File(\"./UPCfaces_hdf5/labels_UPCfaces.hdf5\", \"w\") as f:\n",
    "    dset = f.create_dataset(\"dataset_1\", data=np.array(y))\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 2048) (70,)\n"
     ]
    }
   ],
   "source": [
    "f1 = h5py.File('./UPCfaces_hdf5/data_UPCfaces.hdf5', 'r')\n",
    "X = f1.get('dataset_1').value # `data` is now an ndarray.\n",
    "f1.close()\n",
    "#X = np.array(X)\n",
    "\n",
    "f2 = h5py.File('./UPCfaces_hdf5/labels_UPCfaces.hdf5', 'r')\n",
    "y = f2.get('dataset_1').value # `data` is now an ndarray.\n",
    "f2.close()\n",
    "#y = np.array(y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 2048) (46,) (24, 2048) (24,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state = 6)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "#print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71428571 0.57142857 0.71428571 0.71428571 0.71428571 0.85714286\n",
      " 0.85714286 1.         0.71428571 0.85714286]\n",
      "0.7714285714285715\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9285714285714286, 0.8714285714285716, 0.8142857142857143, 0.8142857142857143, 0.7714285714285715, 0.7857142857142858, 0.7857142857142857, 0.7428571428571429, 0.7285714285714286]\n"
     ]
    }
   ],
   "source": [
    "# search for an optimal value of K for KNN\n",
    "\n",
    "# range of k we want to try\n",
    "k_range = range(1, 10)\n",
    "# empty list to store scores\n",
    "k_scores = []\n",
    "\n",
    "# 1. we will loop through reasonable values of k\n",
    "for k in k_range:\n",
    "    # 2. run KNeighborsClassifier with k neighbours\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # 3. obtain cross_val_score for KNeighborsClassifier with k neighbours\n",
    "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "    # 4. append mean of scores for k neighbors to k_scores list\n",
    "    k_scores.append(scores.mean())\n",
    "\n",
    "\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X, y)\n",
    "\n",
    "#testVec = [x/n for x in [sum(x) for x in newPics]]\n",
    "print(neigh.predict([testVec]))\n",
    "#print(neigh.predict_proba([testVec]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         0.85714286 1.         1.         1.\n",
      " 1.         1.         1.         1.        ]\n",
      "0.9857142857142858\n",
      "17714.271068572998 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf = MLPClassifier(alpha=3.1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "print(\"%s ms\" % ((time.time() - start_time)*1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.85714286 0.85714286 1.         1.         1.\n",
      " 1.         1.         1.         1.        ]\n",
      "0.9714285714285715\n",
      "2683.2423210144043 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf = RandomForestClassifier(max_depth=250, n_estimators=200, max_features=5)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "print(\"%s ms\" % ((time.time() - start_time)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.71428571 0.85714286 1.         1.         1.\n",
      " 0.85714286 1.         0.85714286 0.85714286]\n",
      "0.9142857142857144\n",
      "43.59292984008789 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf = KNeighborsClassifier(n_neighbors=1, p=1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "print(\"%s ms\" % ((time.time() - start_time)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.71428571 0.71428571 0.85714286 0.85714286 0.85714286\n",
      " 1.         0.85714286 0.71428571 0.85714286]\n",
      "0.8428571428571429\n",
      "335.8781337738037 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf = DecisionTreeClassifier(max_depth=250, min_samples_split=2)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "print(\"%s ms\" % ((time.time() - start_time)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaboostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85714286 0.42857143 0.71428571 0.14285714 1.         0.71428571\n",
      " 0.85714286 0.71428571 0.71428571 0.71428571]\n",
      "0.6857142857142857\n",
      "13480.356931686401 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf = AdaBoostClassifier(n_estimators=100, learning_rate = 0.5)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "print(\"%s ms\" % ((time.time() - start_time)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.71428571 0.71428571 0.85714286 0.71428571 0.71428571\n",
      " 1.         0.71428571 1.         0.85714286]\n",
      "0.8285714285714286\n",
      "47.76763916015625 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "print(\"%s ms\" % ((time.time() - start_time)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57142857 0.42857143 0.14285714 0.57142857 0.42857143 0.28571429\n",
      " 0.71428571 0.28571429 0.57142857 0.42857143]\n",
      "0.4428571428571429\n",
      "166.534423828125 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf = SVC(gamma=1, C=1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "print(\"%s ms\" % ((time.time() - start_time)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57142857 0.14285714 0.57142857 0.42857143 0.42857143 0.42857143\n",
      " 0.71428571 0.28571429 0.14285714 0.28571429]\n",
      "0.39999999999999997\n",
      "324.0656852722168 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf = QuadraticDiscriminantAnalysis()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "\n",
    "print(\"%s ms\" % ((time.time() - start_time)*1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
