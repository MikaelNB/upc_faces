{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2048) (100,)\n"
     ]
    }
   ],
   "source": [
    "f1 = h5py.File('data_100_ytf.hdf5', 'r')\n",
    "X = f1.get('dataset_1').value # `data` is now an ndarray.\n",
    "f1.close()\n",
    "#X = np.array(X)\n",
    "\n",
    "f2 = h5py.File('labels_100_ytf.hdf5', 'r')\n",
    "y = f2.get('dataset_1').value # `data` is now an ndarray.\n",
    "f2.close()\n",
    "#y = np.array(y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 2048) (67,) (33, 2048) (33,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state = 6)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "#print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.9800000000000001, 0.97, 0.96, 0.95, 0.9400000000000001, 0.9200000000000002, 0.9100000000000001, 0.9, 0.9, 0.89, 0.86, 0.8400000000000001, 0.8300000000000001, 0.8, 0.7900000000000001, 0.74, 0.74, 0.71, 0.7, 0.6900000000000001, 0.65, 0.62, 0.5900000000000001, 0.5700000000000001, 0.54, 0.5400000000000001, 0.53, 0.5000000000000001, 0.51, 0.5, 0.48, 0.45999999999999996, 0.45, 0.47000000000000003, 0.45999999999999996, 0.45999999999999996, 0.45, 0.44000000000000006, 0.43, 0.43, 0.43, 0.43, 0.42000000000000004, 0.42000000000000004, 0.4, 0.4, 0.38, 0.37, 0.35, 0.35, 0.35, 0.33999999999999997, 0.33999999999999997, 0.32999999999999996, 0.31999999999999995, 0.30999999999999994, 0.29999999999999993, 0.27999999999999997, 0.26999999999999996, 0.25, 0.22000000000000003, 0.21000000000000002, 0.21000000000000002, 0.18, 0.16000000000000003, 0.12000000000000002, 0.11000000000000001, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n"
     ]
    }
   ],
   "source": [
    "# search for an optimal value of K for KNN\n",
    "\n",
    "# range of k we want to try\n",
    "k_range = range(1, 91)\n",
    "# empty list to store scores\n",
    "k_scores = []\n",
    "\n",
    "# 1. we will loop through reasonable values of k\n",
    "for k in k_range:\n",
    "    # 2. run KNeighborsClassifier with k neighbours\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # 3. obtain cross_val_score for KNeighborsClassifier with k neighbours\n",
    "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "    # 4. append mean of scores for k neighbors to k_scores list\n",
    "    k_scores.append(scores.mean())\n",
    "\n",
    "\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=6)\n",
    "neigh.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0\n",
      "60.059547424316406 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf = KNeighborsClassifier(n_neighbors=6, p=1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "print(\"%s ms\" % ((time.time() - start_time)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8 1.  0.9 0.9 0.9 0.8 0.7 0.9 0.7 0.9]\n",
      "0.85\n",
      "752.4216175079346 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf = DecisionTreeClassifier(max_depth=250, min_samples_split=2)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "print(\"%s ms\" % ((time.time() - start_time)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0\n",
      "2584.2485427856445 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf = RandomForestClassifier(max_depth=250, n_estimators=200, max_features=5)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "print(\"%s ms\" % ((time.time() - start_time)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0\n",
      "18689.08166885376 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf = MLPClassifier(alpha=3.1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "print(\"%s ms\" % ((time.time() - start_time)*1000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaboostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9 1.  0.9 1.  0.8 1.  1.  0.9 0.9 0.9]\n",
      "0.93\n",
      "18143.638134002686 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf = AdaBoostClassifier(n_estimators=100, learning_rate = 0.5)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "print(\"%s ms\" % ((time.time() - start_time)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  1.  1.  1.  0.9 0.9 1.  0.9 1.  1. ]\n",
      "0.97\n",
      "58.594703674316406 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "print(\"%s ms\" % ((time.time() - start_time)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7 0.5 0.5 0.4 0.5 0.3 0.7 0.4 0.3 0.3]\n",
      "0.45999999999999996\n",
      "143.3699131011963 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf = QuadraticDiscriminantAnalysis()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "\n",
    "print(\"%s ms\" % ((time.time() - start_time)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.4 0.3 0.8 0.3 0.4 0.2 0.2 0.3 0.2]\n",
      "0.34\n",
      "348.59681129455566 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf = SVC(gamma=1, C=1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "print(\"%s ms\" % ((time.time() - start_time)*1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
