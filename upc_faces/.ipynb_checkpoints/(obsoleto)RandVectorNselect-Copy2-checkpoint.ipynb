{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")  # Adds higher directory to python modules path.\n",
    "from img_to_vec import Img2Vec\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "#import torchvision.models as models\n",
    "# model = models.resnet152(pretrained=True)\n",
    "# modules=list(model.modules())[:-1]\n",
    "# print(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikaelnb/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['faces 01', 'faces 02']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# input_path = './test_images'\n",
    "#input_path = '/home/mikaelnb/Project/notebooks/YouTubeFacesDB/data'\n",
    "input_path = './faces/'\n",
    "\n",
    "img2vec = Img2Vec(model='resnet-152')\n",
    "\n",
    "os.listdir(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['faces 01', 'faces 02'] {0: 'faces 01', 1: 'faces 02'}\n"
     ]
    }
   ],
   "source": [
    "#aligned_folder = '/aligned_images_DB/'\n",
    "new_input_path = input_path# + aligned_folder\n",
    "labels = sorted(os.listdir(new_input_path), key=lambda s: s.lower())#[:4]\n",
    "label_id = {}\n",
    "for i, label in enumerate(labels):\n",
    "    label_id[i] = label\n",
    "print(labels, label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in os.listdir(new_input_path + label):\n",
    "#     print(os.fsdecode(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faces 01\n",
      "faces 02\n"
     ]
    }
   ],
   "source": [
    "for asdfdas in label_id:\n",
    "    print(label_id[asdfdas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[None, None]\n",
      "[[], []]\n"
     ]
    }
   ],
   "source": [
    "print(len(label_id))\n",
    "#pics = np.empty((len(label_id),0))\n",
    "pics = [None]*len(label_id)\n",
    "print(pics)\n",
    "\n",
    "for index in label_id:\n",
    "    pics[int(index)] = []\n",
    "    \n",
    "print(pics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "index:  1\n",
      "(2048,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikaelnb/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "(2048,)\n",
      "\n",
      "[[0.4897556  0.6178684  0.4587147  ... 0.08357252 0.13227662 0.03964458]\n",
      " [0.33301446 0.49266303 0.24831617 ... 0.10234171 0.18132412 0.02051125]\n",
      " [0.35004497 0.707076   0.27862468 ... 0.09606014 0.09778297 0.01891252]\n",
      " ...\n",
      " [0.23505151 0.5837828  0.27997777 ... 0.11564807 0.08962566 0.00293765]\n",
      " [0.34655672 0.6855115  0.37316924 ... 0.07507481 0.08643005 0.01282592]\n",
      " [0.28624165 0.6992103  0.35752058 ... 0.06303831 0.3011419  0.0007719 ]]\n",
      "[[0.1085029  1.0993     0.290269   ... 0.05480364 0.1790252  0.06140967]\n",
      " [0.11338018 0.95706195 0.21444765 ... 0.0196206  0.29912144 0.13165691]\n",
      " [0.11225048 0.7576683  0.30352062 ... 0.05828168 0.19530435 0.12944102]\n",
      " ...\n",
      " [0.03646005 1.2269812  0.2856023  ... 0.05246621 0.15191537 0.021313  ]\n",
      " [0.28915977 0.8346639  0.2016013  ... 0.05534095 0.24143694 0.17353797]\n",
      " [0.34739187 0.8286959  0.37461925 ... 0.0819678  0.19980785 0.0635678 ]]\n"
     ]
    }
   ],
   "source": [
    "vec = []\n",
    "labels = []\n",
    "imagesPerLabel = 50\n",
    "\n",
    "testVec = []\n",
    "k = 0\n",
    "for index in label_id:    \n",
    "    for root, dirs, files in os.walk(new_input_path + label_id[index]):\n",
    "        #print(root, dirs, files)\n",
    "        for name in files:\n",
    "            if len(pics[index]) > imagesPerLabel:\n",
    "                print(index, len(pics[index]))\n",
    "                break\n",
    "            #print(name)\n",
    "            if name.endswith((\".jpg\")):                \n",
    "                img = Image.open(os.path.join(os.fsdecode(root), name))\n",
    "                #print(os.path.join(os.fsdecode(root), name))\n",
    "                vec = img2vec.get_vec(img)\n",
    "                if  testVec == [] and index == 1:\n",
    "                    k += 1\n",
    "                    if k == 30:\n",
    "                        print('index: ', index)\n",
    "                        testVec = vec\n",
    "                print(vec.shape)                \n",
    "                pics[index].append(vec)     \n",
    "                #print(name)\n",
    "                \n",
    "    pics[index] = np.array(pics[index])    \n",
    "    labels.append(int(index))\n",
    "labels = np.array(labels)\n",
    "\n",
    "print()\n",
    "print(pics[0][0:])\n",
    "print(pics[1][0:])\n",
    "\n",
    "#                 X = vec.T\n",
    "#                 num_components = 128\n",
    "#                 pca = PCA(n_components = num_components, whiten=True).fit(X)\n",
    "\n",
    "#                 X_train = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 49, 2048)\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "pics=np.array(pics)\n",
    "print(pics.shape)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[13,\n",
       "  25,\n",
       "  29,\n",
       "  43,\n",
       "  6,\n",
       "  37,\n",
       "  42,\n",
       "  21,\n",
       "  44,\n",
       "  45,\n",
       "  17,\n",
       "  22,\n",
       "  5,\n",
       "  33,\n",
       "  26,\n",
       "  35,\n",
       "  20,\n",
       "  2,\n",
       "  18,\n",
       "  27,\n",
       "  3,\n",
       "  34,\n",
       "  19,\n",
       "  1,\n",
       "  38],\n",
       " [44,\n",
       "  26,\n",
       "  36,\n",
       "  25,\n",
       "  38,\n",
       "  10,\n",
       "  1,\n",
       "  19,\n",
       "  7,\n",
       "  8,\n",
       "  40,\n",
       "  12,\n",
       "  37,\n",
       "  14,\n",
       "  39,\n",
       "  46,\n",
       "  35,\n",
       "  47,\n",
       "  27,\n",
       "  24,\n",
       "  4,\n",
       "  42,\n",
       "  30,\n",
       "  11,\n",
       "  20]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "n=25\n",
    "randList=[]\n",
    "\n",
    "for i in range(0,len(pics)):\n",
    "    randList.append(random.sample(range(imagesPerLabel), n))\n",
    "randList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randList[0][0]\n",
    "# test = np.vstack(pics[0][9])\n",
    "# print(test, pics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPics = [None]*len(label_id)\n",
    "for index in label_id:\n",
    "    newPics[int(index)] = []\n",
    "    \n",
    "for index in range(0,len(pics)):\n",
    "    for i in range(0, n):\n",
    "        newPics[index].append(pics[index][randList[index][i]])\n",
    "    newPics[index] = np.array(newPics[index])\n",
    "newPics = np.array(newPics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([11.346179 , 17.473856 , 10.340357 , ...,  2.7392592,  4.4319105,\n",
      "        0.4416565], dtype=float32), array([ 4.055043 , 22.583017 ,  6.3073034, ...,  1.6351601,  6.31026  ,\n",
      "        2.539989 ], dtype=float32)]\n",
      "[array([0.45384717, 0.6989542 , 0.41361427, ..., 0.10957037, 0.17727642,\n",
      "       0.01766626], dtype=float32), array([0.16220173, 0.90332067, 0.25229213, ..., 0.0654064 , 0.25241038,\n",
      "       0.10159956], dtype=float32)]\n",
      "(2, 2048) (2,)\n"
     ]
    }
   ],
   "source": [
    "print([sum(x) for x in newPics])\n",
    "print([x/n for x in [sum(x) for x in newPics]])\n",
    "X = [x/n for x in [sum(x) for x in newPics]]\n",
    "y = labels\n",
    "X = np.array(X)\n",
    "#y = np.array(y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-92364ce614ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestVec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#print(neigh.predict_proba([testVec]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mikaelnb/.local/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m             )\n\u001b[1;32m    349\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 3"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X, y)\n",
    "\n",
    "print(neigh.predict([testVec]))\n",
    "#print(neigh.predict_proba([testVec]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mydataset /\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with h5py.File(\"data.hdf5\", \"w\") as f:\n",
    "    dset = f.create_dataset(\"dataset_1\", data=np.array(pics))\n",
    "    print(dset.name, f.name)\n",
    "with h5py.File(\"labels.hdf5\", \"w\") as f:\n",
    "    dset = f.create_dataset(\"dataset_1\", (100,), dtype='i')\n",
    "    print(dset.name, f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('mytestfile.hdf5', 'r+')\n",
    "grp = f.create_group(\"subgroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pics.shape)\n",
    "pca = PCA(n_components=128)       \n",
    "pca.fit(pics['Aaron_Eckhart'])\n",
    "pca.shape\n",
    "print(len(pics['Aaron_Eckhart']))\n",
    "print(len(pics['Aaron_Eckhart'][0]))\n",
    "pics['Aaron_Eckhart'] = pca.transform(pics['Aaron_Eckhart'])\n",
    "print(pca.fit(pics['Aaron_Eckhart'][0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "print(len(pics['Aaron_Eckhart']))\n",
    "print(len(pics['Aaron_Eckhart'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pics = {}\n",
    "# for file in os.listdir(input_path):\n",
    "#     filename = os.fsdecode(file)\n",
    "#     img = Image.open(os.path.join(input_path, filename))\n",
    "#     vec = img2vec.get_vec(img)\n",
    "#     pics[filename] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For each test image, we store the filename and vector as key, value in a dictionary\n",
    "\n",
    "# pics = {}\n",
    "# for file in os.listdir(input_path):\n",
    "#     filename = os.fsdecode(file)\n",
    "#     img = Image.open(os.path.join(input_path, filename))\n",
    "#     vec = img2vec.get_vec(img)\n",
    "#     pics[filename] = vec\n",
    "\n",
    "# pic_name = \"\"\n",
    "# while pic_name != \"exit\":\n",
    "#     pic_name = str(input(\"Which filename would you like similarities for?\\n\"))\n",
    "\n",
    "#     try:\n",
    "#         sims = {}\n",
    "#         for key in list(pics.keys()):\n",
    "#             if key == pic_name:\n",
    "#                 continue\n",
    "\n",
    "#             sims[key] = cosine_similarity(pics[pic_name].reshape((1, -1)), pics[key].reshape((1, -1)))[0][0]\n",
    "\n",
    "#         d_view = [(v, k) for k, v in sims.items()]\n",
    "#         d_view.sort(reverse=True)\n",
    "#         for v, k in d_view:\n",
    "#             print(v, k)\n",
    "\n",
    "#     except KeyError as e:\n",
    "#         print('Could not find filename %s' % e)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
