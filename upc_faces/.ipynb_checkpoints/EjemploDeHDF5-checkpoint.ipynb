{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import h5py\n",
    "import numpy as np\n",
    "sys.path.append(\"..\")  # Adds higher directory to python modules path.\n",
    "from img_to_vec import Img2Vec\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#import torchvision.models as models\n",
    "# model = models.resnet152(pretrained=True)\n",
    "# modules=list(model.modules())[:-1]\n",
    "# print(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikaelnb/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['frame_images_DB',\n",
       " 'sources',\n",
       " 'headpose_DB',\n",
       " 'meta_data',\n",
       " 'aligned_images_DB',\n",
       " 'images.txt',\n",
       " 'descriptors_DB']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# input_path = './test_images'\n",
    "input_path = '/home/mikaelnb/Project/notebooks/YouTubeFacesDB/data'\n",
    "\n",
    "img2vec = Img2Vec(model='resnet-152')\n",
    "\n",
    "os.listdir(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aaron_Eckhart', 'Aaron_Guiel', 'Aaron_Sorkin', 'Aaron_Tippin'] {0: 'Aaron_Eckhart', 1: 'Aaron_Guiel', 2: 'Aaron_Sorkin', 3: 'Aaron_Tippin'}\n"
     ]
    }
   ],
   "source": [
    "aligned_folder = '/aligned_images_DB/'\n",
    "new_input_path = input_path + aligned_folder\n",
    "unique_labels = sorted(os.listdir(new_input_path), key=lambda s: s.lower())[:4]\n",
    "label_id = {}\n",
    "for i, label in enumerate(unique_labels):\n",
    "    label_id[i] = label\n",
    "print(unique_labels, label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in os.listdir(new_input_path + label):\n",
    "#     print(os.fsdecode(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aaron_Eckhart\n",
      "Aaron_Guiel\n",
      "Aaron_Sorkin\n",
      "Aaron_Tippin\n"
     ]
    }
   ],
   "source": [
    "for i in label_id:\n",
    "    print(label_id[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[[], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "print(len(label_id))\n",
    "pics = [None]*len(label_id)\n",
    "for index in label_id:\n",
    "    pics[int(index)]=[]\n",
    "print(pics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mikaelnb/Project/notebooks/YouTubeFacesDB/data/aligned_images_DB/Aaron_Eckhart/0/aligned_detect_0.618.jpg\n",
      "[0.12123615 0.53908724 0.26128197 ... 0.07301539 0.4374354  0.05983448]\n",
      "/home/mikaelnb/Project/notebooks/YouTubeFacesDB/data/aligned_images_DB/Aaron_Eckhart/1/aligned_detect_1.193.jpg\n",
      "[0.55311847 0.7909895  0.29453588 ... 0.29483855 0.38080034 0.01803491]\n",
      "/home/mikaelnb/Project/notebooks/YouTubeFacesDB/data/aligned_images_DB/Aaron_Eckhart/2/aligned_detect_2.1766.jpg\n",
      "[0.00584774 0.5461705  0.7345729  ... 0.26277387 0.35868496 0.19112445]\n",
      "/home/mikaelnb/Project/notebooks/YouTubeFacesDB/data/aligned_images_DB/Aaron_Guiel/5/aligned_detect_5.2002.jpg\n",
      "[0.5466309  0.04706439 0.6879376  ... 0.2440265  0.17259432 0.0535282 ]\n",
      "/home/mikaelnb/Project/notebooks/YouTubeFacesDB/data/aligned_images_DB/Aaron_Sorkin/0/aligned_detect_0.112.jpg\n",
      "[0.16631442 0.12690876 0.24870096 ... 0.15881693 0.28701308 0.13031588]\n",
      "/home/mikaelnb/Project/notebooks/YouTubeFacesDB/data/aligned_images_DB/Aaron_Sorkin/3/aligned_detect_3.428.jpg\n",
      "[0.31273007 0.39718616 0.29012015 ... 0.08095735 0.5145007  0.04541151]\n",
      "/home/mikaelnb/Project/notebooks/YouTubeFacesDB/data/aligned_images_DB/Aaron_Tippin/0/aligned_detect_0.441.jpg\n",
      "[0.07709163 0.49493518 0.5575198  ... 0.01064472 0.32209712 0.00447595]\n",
      "/home/mikaelnb/Project/notebooks/YouTubeFacesDB/data/aligned_images_DB/Aaron_Tippin/1/aligned_detect_1.1602.jpg\n",
      "[0.07130029 0.43422395 0.32589325 ... 0.22808737 0.10837307 0.        ]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "features = []\n",
    "vec = []\n",
    "\n",
    "for index in label_id: \n",
    "    for root, dirs, files in os.walk(new_input_path + label_id[index]):\n",
    "        for name in files:\n",
    "            if name.endswith((\".jpg\")):\n",
    "                img = Image.open(os.path.join(os.fsdecode(root), name))\n",
    "                print(os.path.join(os.fsdecode(root), name))\n",
    "                vec = img2vec.get_vec(img)\n",
    "                \n",
    "                labels.append(label_id[index])\n",
    "                features.append(vec)\n",
    "                \n",
    "                print(vec)                \n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.12123615, 0.53908724, 0.26128197, ..., 0.07301539, 0.4374354 ,\n",
      "       0.05983448], dtype=float32), array([0.55311847, 0.7909895 , 0.29453588, ..., 0.29483855, 0.38080034,\n",
      "       0.01803491], dtype=float32), array([0.00584774, 0.5461705 , 0.7345729 , ..., 0.26277387, 0.35868496,\n",
      "       0.19112445], dtype=float32), array([0.5466309 , 0.04706439, 0.6879376 , ..., 0.2440265 , 0.17259432,\n",
      "       0.0535282 ], dtype=float32), array([0.16631442, 0.12690876, 0.24870096, ..., 0.15881693, 0.28701308,\n",
      "       0.13031588], dtype=float32), array([0.31273007, 0.39718616, 0.29012015, ..., 0.08095735, 0.5145007 ,\n",
      "       0.04541151], dtype=float32), array([0.07709163, 0.49493518, 0.5575198 , ..., 0.01064472, 0.32209712,\n",
      "       0.00447595], dtype=float32), array([0.07130029, 0.43422395, 0.32589325, ..., 0.22808737, 0.10837307,\n",
      "       0.        ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(features)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(al parecer no es necesario hacer vstack)\n",
    "#features=np.vstack(features)\n",
    "features=np.transpose(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aaron_Eckhart', 'Aaron_Eckhart', 'Aaron_Eckhart', 'Aaron_Guiel', 'Aaron_Sorkin', 'Aaron_Sorkin', 'Aaron_Tippin', 'Aaron_Tippin']\n",
      "[[0.12123615 0.55311847 0.00584774 0.5466309  0.16631442 0.31273007\n",
      "  0.07709163 0.07130029]]\n",
      "(2048, 8)\n"
     ]
    }
   ],
   "source": [
    "print(labels[0:8])\n",
    "print(features[0:][0:1])\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"data.hdf5\", \"w\") as f:\n",
    "    dset = f.create_dataset(\"dataset_1\", data=np.array(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "target = le.fit_transform(labels)\n",
    "with h5py.File(\"labels.hdf5\", \"w\") as f:\n",
    "    dset = f.create_dataset(\"dataset_1\", data=np.array(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('mytestfile.hdf5', 'r+')\n",
    "grp = f.create_group(\"subgroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pics.shape)\n",
    "pca = PCA(n_components=128)       \n",
    "pca.fit(pics['Aaron_Eckhart'])\n",
    "pca.shape\n",
    "print(len(pics['Aaron_Eckhart']))\n",
    "print(len(pics['Aaron_Eckhart'][0]))\n",
    "pics['Aaron_Eckhart'] = pca.transform(pics['Aaron_Eckhart'])\n",
    "print(pca.fit(pics['Aaron_Eckhart'][0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "print(len(pics['Aaron_Eckhart']))\n",
    "print(len(pics['Aaron_Eckhart'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pics = {}\n",
    "# for file in os.listdir(input_path):\n",
    "#     filename = os.fsdecode(file)\n",
    "#     img = Image.open(os.path.join(input_path, filename))\n",
    "#     vec = img2vec.get_vec(img)\n",
    "#     pics[filename] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For each test image, we store the filename and vector as key, value in a dictionary\n",
    "\n",
    "# pics = {}\n",
    "# for file in os.listdir(input_path):\n",
    "#     filename = os.fsdecode(file)\n",
    "#     img = Image.open(os.path.join(input_path, filename))\n",
    "#     vec = img2vec.get_vec(img)\n",
    "#     pics[filename] = vec\n",
    "\n",
    "# pic_name = \"\"\n",
    "# while pic_name != \"exit\":\n",
    "#     pic_name = str(input(\"Which filename would you like similarities for?\\n\"))\n",
    "\n",
    "#     try:\n",
    "#         sims = {}\n",
    "#         for key in list(pics.keys()):\n",
    "#             if key == pic_name:\n",
    "#                 continue\n",
    "\n",
    "#             sims[key] = cosine_similarity(pics[pic_name].reshape((1, -1)), pics[key].reshape((1, -1)))[0][0]\n",
    "\n",
    "#         d_view = [(v, k) for k, v in sims.items()]\n",
    "#         d_view.sort(reverse=True)\n",
    "#         for v, k in d_view:\n",
    "#             print(v, k)\n",
    "\n",
    "#     except KeyError as e:\n",
    "#         print('Could not find filename %s' % e)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
