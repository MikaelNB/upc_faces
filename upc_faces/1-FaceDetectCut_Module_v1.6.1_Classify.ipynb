{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "import sys\n",
    "import cv2\n",
    "import argparse\n",
    "import time\n",
    "import tkinter as tki\n",
    "import threading\n",
    "from PIL import Image\n",
    "from PIL import ImageTk\n",
    "#sys.path.append(\"..\")  # Adds higher directory to python modules path.\n",
    "#from img_to_vec import Img2Vec\n",
    "#from PIL import Image\n",
    "\n",
    "import socket\n",
    "import pickle\n",
    "import struct\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FaceDetector Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetector:\n",
    "    def __init__(self, detector = 'haar', standalone = False, output = './UPCfacesB/', samples = 50):\n",
    "        self.root = tki.Tk()\n",
    "        self.panel = None\n",
    "        self.thread = None\n",
    "        self.detector = detector\n",
    "        self.standalone = standalone\n",
    "        self.video = cv2.VideoCapture('/dev/video0')\n",
    "        #self.img2vec = Img2Vec(model='resnet-152')\n",
    "        self.samples = samples\n",
    "        self.pause = False\n",
    "        self.wait = 15\n",
    "        self.margin = 55\n",
    "        self.cascPath = ''\n",
    "        if self.detector == 'haar':\n",
    "            self.cascPath=\"haarcascade_frontalface_alt2.xml\"\n",
    "        elif self.detector == 'lbp': \n",
    "            self.cascPath=\"lbpcascade_frontalface_improved.xml\"\n",
    "        else:\n",
    "            exit()\n",
    "        self.faceCascade=cv2.CascadeClassifier(self.cascPath)\n",
    "        self.output = output\n",
    "        self.new_dir = ''\n",
    "        self.end = False\n",
    "        self.id = 0\n",
    "        \n",
    "    def CreateDatasetDir(self):        \n",
    "        try:\n",
    "            # Create target Directory\n",
    "            os.mkdir(self.output)\n",
    "            print(\"Directory\" , self.output ,  \"Created \")\n",
    "        except FileExistsError:\n",
    "            print(\"Directory\" , self.output ,  \"already exists\")\n",
    "\n",
    "    def SetupDir(self):\n",
    "\n",
    "        dirs = os.listdir(self.output)\n",
    "        \n",
    "        if len(dirs) > 0 and len(os.listdir(self.output + 'faces_' + str(len(dirs)) + '/') ) < self.samples:\n",
    "            print('Directory is less than {} samples'.format(self.samples))\n",
    "            self.new_dir = self.output + 'faces_' + str(len(dirs)) + '/'\n",
    "            for the_file in os.listdir(self.new_dir):\n",
    "                file_path = os.path.join(self.new_dir, the_file)\n",
    "                try:\n",
    "                    if os.path.isfile(file_path):\n",
    "                        os.unlink(file_path)\n",
    "                    #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "            print('Directory' , self.new_dir, len(os.listdir(self.new_dir)) ,  'gets overwritten')\n",
    "        else:    \n",
    "            print('Directory is not empty')\n",
    "            self.new_dir = self.output + 'faces_' + str(len(dirs)+1) + '/'\n",
    "            try:\n",
    "                os.mkdir(self.new_dir)\n",
    "                print('Directory' , self.new_dir ,  'created')\n",
    "            except FileExistsError as e:\n",
    "                        print(e)\n",
    "        \n",
    "    def Detect(self):        \n",
    "        k = 0\n",
    "        frame_it=-1\n",
    "        face_it=0\n",
    "        ret, frame=self.video.read()\n",
    "        mask = np.zeros(frame.shape[:],dtype=np.uint8)\n",
    "        x0 = 0\n",
    "        y0 = 0\n",
    "        accum = 0\n",
    "        index = []\n",
    "        #vec = N\n",
    "        crops = []\n",
    "        while not self.end:\n",
    "            \n",
    "            ret, frame=self.video.read()\n",
    "            if ret:\n",
    "                frame_it+=1\n",
    "                #gray=cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "                faces=self.faceCascade.detectMultiScale(frame,scaleFactor=1.01,minNeighbors=3,minSize=(140,140),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "                if k == 0 and len(faces) > 0:\n",
    "                    self.SetupDir()\n",
    "                mask = np.zeros(frame.shape[:],dtype=np.uint8)\n",
    "                for (x,y,w,h) in faces:\n",
    "                    if (x0 == 0 and y0 == 0) or abs(x-x0)+abs(y-y0) < self.margin:\n",
    "                        face_it+=1\n",
    "                        mask=cv2.ellipse(mask,(x+w//2,y+int(h/2)),(int(w/3),int(h/2)),0,0,360,(255,255,255),-1)\n",
    "                        mask=np.bitwise_and(frame,mask)\n",
    "                        crop=mask[y:y+h,x:x+w]\n",
    "                        crop = cv2.resize(crop, (140, 140)) \n",
    "                        crops.append(np.array(crop))\n",
    "                        cv2.imshow('Crop',crops[-1])\n",
    "                        \n",
    "#                         image = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "#                         image = Image.fromarray(image)\n",
    "#                         image = ImageTk.PhotoImage(image)\n",
    "                        \n",
    "#                         if self.panel is None:\n",
    "#                             self.panel = tki.Label(image=image)\n",
    "#                             self.panel.image = image\n",
    "#                             self.panel.pack(side=\"left\", padx=10, pady=10)\n",
    "#                         else:\n",
    "#                             self.panel.configure(image=image)\n",
    "#                             self.panel.image = image\n",
    "\n",
    "\n",
    "                        #start = time.time()\n",
    "                        #vec = self.img2vec.get_vec(Image.fromarray(crop))\n",
    "                        #end = time.time()\n",
    "                        #print(end - start, 'secs')\n",
    "                        #print(vec.shape)\n",
    "                        cv2.imwrite(self.new_dir + 'fr{}_f{}.jpg'.format(frame_it,face_it),crop)\n",
    "                        \n",
    "                        k += 1\n",
    "#                         x0 = x\n",
    "#                         y0 = y\n",
    "#                         accum = 0\n",
    "#                     elif abs(x-x0)+abs(y-y0) >= self.margin:\n",
    "#                         accum += 1\n",
    "\n",
    "                for (x,y,w,h) in faces:\n",
    "                    if (x0 == 0 and y0 == 0) or abs(x-x0)+abs(y-y0) < self.margin:\n",
    "                        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "                        x0 = x\n",
    "                        y0 = y\n",
    "                        accum = 0\n",
    "                    elif abs(x-x0)+abs(y-y0) >= self.margin:\n",
    "                        accum += 1\n",
    "\n",
    "                if accum > self.wait:\n",
    "                    accum = 0\n",
    "                    x0 = y0 = 0\n",
    "\n",
    "                cv2.imshow('Video',frame)\n",
    "                #if len(faces) > 0:\n",
    "                    #print('Num Faces: {0}, ({1}, {2})'.format(len(faces), int(x0), int(y0)),end='\\r')\n",
    "                c = cv2.waitKey(1)\n",
    "                if c & 0xFF == ord('q'):\n",
    "                    self.end = True                    \n",
    "                    break\n",
    "                \n",
    "                if c & 0xFF == ord('p'):\n",
    "                    self.pause = True\n",
    "                    print('Detection Paused')\n",
    "                \n",
    "                if (k >= self.samples):\n",
    "                    #data = pickle.dumps(np.array(crops))\n",
    "                    #clientsocket.sendall(struct.pack(\"L\", len(data)) + data)\n",
    "                    print('Capture Success')\n",
    "                    self.pause = True\n",
    "                    \n",
    "                if self.pause:\n",
    "                    crops = []\n",
    "                    k = 0\n",
    "                    face_it = 0\n",
    "                    frame_it = -1\n",
    "                    self.IdleVideo()\n",
    "                    #self.Detect()\n",
    "        self.video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "\n",
    "        \n",
    "    def IdleVideo(self):\n",
    "\n",
    "        while self.pause:\n",
    "            ret, frame = self.video.read()\n",
    "            if ret:\n",
    "                cv2.imshow('Video',frame)\n",
    "                c = cv2.waitKey(1)\n",
    "                if c & 0xFF == ord('q'):\n",
    "                    self.end = True\n",
    "                    break\n",
    "                if c & 0xFF==ord('u'):\n",
    "                    self.pause = False\n",
    "                    print('Detection Resumed')\n",
    "#                     elif 0xFF==ord('q'): \n",
    "#                         self.video.release()\n",
    "#                         cv2.destroyAllWindows()\n",
    "#                         break\n",
    "        \n",
    "                    \n",
    "            \n",
    "        \n",
    "            \n",
    "# def main():\n",
    "#   parser = argparse.ArgumentParser()\n",
    "#   parser.add_argument('foo')\n",
    "#   parser.add_argument('bar')\n",
    "#   args = parser.parse_args()\n",
    "#   c1 = MyClass(args.foo, args.bar)\n",
    "#   args_dict = vars(args)\n",
    "#   c2 = MyClass(**args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ./UPCfacesB/ already exists\n",
      "Directory is less than 10 samples\n",
      "Directory ./UPCfacesB/faces_218/ 0 gets overwritten\n",
      "Capture Success\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    fd = FaceDetector(samples=10)\n",
    "    fd.CreateDatasetDir()\n",
    "    fd.Detect()\n",
    "    \n",
    "#clientsocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "#clientsocket.connect(('127.0.0.1', 8085))    \n",
    "main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crops' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d795bcb90b3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimg_to_vec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImg2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcrop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcrops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'crops' is not defined"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"..\") \n",
    "from img_to_vec import Img2Vec\n",
    "vecs = []\n",
    "for crop in crops:\n",
    "    img = Image.fromarray(np.uint8(crop))    \n",
    "    vec = img2vec.get_vec(img)\n",
    "    vecs.append(vec)\n",
    "print(vecs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 2048) (70,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "f1 = h5py.File('./UPCfaces_hdf5/data_UPCfaces.hdf5', 'r')\n",
    "X = f1.get('dataset_1').value # `data` is now an ndarray.\n",
    "f1.close()\n",
    "#X = np.array(X)\n",
    "\n",
    "f2 = h5py.File('./UPCfaces_hdf5/labels_UPCfaces.hdf5', 'r')\n",
    "y = f2.get('dataset_1').value # `data` is now an ndarray.\n",
    "f2.close()\n",
    "#y = np.array(y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
